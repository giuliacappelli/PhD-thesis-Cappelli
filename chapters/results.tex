% \setchapterstyle{kao}
\setchapterpreamble[u]{\margintoc}
\chapter{Exploring the acceptability judgments}
\labch{results}


\section{Making sense of the results: computational implementation} \labsec{likert_scripts}

\subsection{Operative pipeline} \labsec{likert_pipeline}

This paragraph outlines the technical steps needed to obtain the same results I got using the same scripts I coded, for the sake of replicability. I am improving on the operative pipeline employed by \textcite{Medina2007}, which implied collecting judgments on an undisclosed platform and creating a Stochastic Optimality Theoretic model by means of Excel Solver, both because I use non-proprietary software and languages one can download and use for free, and because I am making my Python scripts and raw input data publicly accessible. As pointed out before, all the raw input data necessary to run my scripts, which in this case are the Likert judgments provided by human participants to the experiment in \refch{judgments}, are available \href{https://github.com/giuliacappelli/dissertationData}{in a dedicated GitHub repository}\footnote{https://github.com/giuliacappelli/dissertationData}.\\
Since the script taking care of the data pre-processing, preliminary analysis, and model creation are designed to work on the barest of input data (i.e. lacking any platform-dependent additional information such as datestamps, operative systems, etc.), the first step in this pipeline is the cleansing and reshaping of the output generated in the PsychoPy-Pavlovia-Prolific process of judgment gathering detailed in \refsec{participants}. This result can be achieved using \href{https://github.com/giuliacappelli/PsychopyToMedina}{my dedicated script}\footnote{https://github.com/giuliacappelli/PsychopyToMedina} on GitHub, which takes care of taking the full Pavlovia-generated file as input and yielding a tabular output with the minimal information necessary to run my Stochastic Optimality Theoretic analysis. The script also anonymizes the participants' names to make the data shareable, and it can (optionally, depending on the experimenter's needs) filter out any participant providing polar either-1-or-7 judgments when prompted to make full use of the 7-point Likert scale.\\
The judgments are now ready to be processed with \href{https://github.com/giuliacappelli/MedinaStochasticOptimalityTheory}{the main Python program}\footnote{https://github.com/giuliacappelli/MedinaStochasticOptimalityTheory}, which requires an input comprised of columns for the verb lemmas, the sentence type (target, control or filler), a column for each predictor of object drop in the desired model, and a column with the judgments provided by each participant in the experiment. This script preprocesses the judgments as described in \refsec{likert_preprocessing}, generates the data used in the analysis provided in this Chapter, and models the judgments according to the Stochastic Optimality Theory requirements described in \refch{modeltheory} (final results in \refch{model}).

\subsection{Data preprocessing} \labsec{likert_preprocessing}

Before moving forward to the actual data analysis and modeling, the main script carries out three preprocessing steps:
\begin{enumerate}
    \item computing the min-max normalized semantic selectivity values for Resnik's SPS, Computational PISA, and Behavioral PISA input files (first introduced in \refsec{predictor_sps}), to make the results comparable across models;
    \item multiplying the semantic selectivity score of each verb by its Zipf value (first introduced in \refsec{verbs}), i.e. the base 10 logarithm of the frequency-per-billion-words of the verb in a given corpus, to avoid having the verb's frequency confound the information provided by the semantic selectivity models;
    \item computing the within-subject z-scores for the judgments, then averaging these scores to obtain the mean judgment for each sentence in the stimuli list, then normalizing the mean judgments between 0 and 1 (following the technique by \textcite{KimEtAl2018, KimEtAl2019, KimEtAl2019a}), to account for inevitable differences in the way each participant makes use of the Likert scale.
\end{enumerate}

This kind of preprocessing also improves on \textcite{Medina2007}'s setting, where both semantic selectivity and judgment data were analysed raw, because it minimizes the potentially disruptive influence of external factors such as corpus frequencies and individual differences in humans on the final Stochastic Optimality Theoretic model of object drop.\\
In the next sections, following \textcite{Medina2007}, I will provide a thorough description of the way the acceptability judgments pertaining the implicit object construction are influenced by each factor separately and by all the factors together, both in English and in Italian. This analysis will demonstrate that a comprenehsive Stochastic Optimality Theoretic model of object drop based on all five predictors in \refch{predictors} is indeed feasible. The model itself is presented and discussed in \refch{model}.


\section{English results} \labsec{eng_judgresult}

\subsection{Semantic selectivity}

The effect of semantic selectivity on the acceptability of the implicit object in English is quantified by means of a Pearson correlation between them. The results of this computation are visualized in \reffig{explore_eng_semsel_sps} for Resnik's SPS, in \reffig{explore_eng_semsel_cpisa} for Computational PISA, and in \reffig{explore_eng_semsel_bpisa} for Behavioral PISA.\\
The first thing to strike the eye of the observer is that the three models of semantic selectivity correlate with varying degrees of accuracy with the human judgments. Unsurprisingly the Selectional Preference Strength, a now-classic measure by \textcite{Resnik1993,Resnik1996}, yields unsatisfactory results which fall quite short of statistical significance. Computational PISA performs much better, with significant (p = 0.038) results, even though the correlation between it and the judgments is very modest (Pearson's $\rho$ = 0.381). Finally, Behavioral PISA appears to be by far the best-performing model of semantic selectivity, with a Pearson's $\rho$ of 0.494 against human judgments and a p value of 0.006.\\ 
Keeping in mind what I concluded about the three models of semantic selectivity back in \refsec{evalMySPSs} (see \reftab{sps_correlmatrix_eng} in particular), these results should not come as a surprise. Indeed, being the gold standard of semantic selectivity models due to being based on human judgments, Behavioral PISA is expected to yield the best results among the three models used here. Computational PISA correlated quite well with the Behavioral PISA benchmark, and we can see that it also correlates nicely with the acceptability judgments regarding the implicit object construction. Resnik's SPS, on the contrary, was found to be a poor model of semantic selectivity if compared to Behavioral PISA, and it is also a poor fit if compared to human ratings about object drop. The good performance of Computational PISA and Behavioral PISA against Resnik's SPS can be explained by referring to the way these models were created, since both PISA models are based on pairwise similarity scores between pairs of direct objects for a given verb, while Resnik's SPS is a taxonomy-based measure.\\
All in all, semantic selectivity (especially the PISA models) is not a bad predictor of object drop in English, but it's far from being a reliable one when considered in isolation from all the other possible ones.

% parlare dei singoli puntini rilevanti?


\begin{figure}[htb]
\caption{Correlation between semantic selectivity (Resnik's SPS) and normalized acceptability judgments on object drop in English.}
\labfig{explore_eng_semsel_sps}
    \input figures/ukwac_preliminary_scatterplot_SPS.tex
\end{figure}

\begin{figure}[htb]
\caption{Correlation between semantic selectivity (Computational PISA) and normalized acceptability judgments on object drop in English.}
\labfig{explore_eng_semsel_cpisa}
    \input figures/ukwac_preliminary_scatterplot_Computational_PISA.tex
\end{figure}

\begin{figure}[htb]
\caption{Correlation between semantic selectivity (Behavioral PISA) and normalized acceptability judgments on object drop in English.}
\labfig{explore_eng_semsel_bpisa}
    \input figures/ukwac_preliminary_scatterplot_Behavioral_PISA.tex
\end{figure}


\subsection{Binary predictors} 

\paragraph{Telicity}
The boxplots in \reffig{explore_eng_telicity} illustrate the main effect of telicity on the acceptability judgments on the implicit object construction in English. A Mann-Whitney U test reveals that telic verbs were judged as significantly (p < 0.0001) less grammatical than atelic verbs, consistently with expectations (refer back to \refsec{telicity} and \refsec{predictor_telicity}).\\
Despite the statistical significance of the difference between the ratings of telic and atelic verbs, it is not the case that all telic verbs receive ratings below a given threshold and all atelic verbs receive ratings above it. On the contrary, judgments for telic verbs span almost all the way from 0 to 1, and while judgments for atelic verbs have a much tighter distribution (with their interquartile range\sidenote{The interquartile range is the difference between the first quartile and the third quartile, which are the medians of the lower and the upper half of the dataset, respectively. Graphically, it is rendered as the so-called "box" in the boxplot. The other parts of a boxplot are the median (second quartile), cutting in half the interquartile range, and the so-called "whiskers", i.e. the minimum and maximum values in the dataset. Outliers are shown here as little diamonds outside of the boundaries traced by the whiskers.} being fully above the interquartile range for telic verbs), they still overlap in a non-negligible way.\\
testo

% motivare l'outlier

\begin{figure}[htb]
\caption{Effect of telicity on normalized acceptability judgments about object drop in English.}
\labfig{explore_eng_telicity}
    \input figures/ukwac_star_boxplot_telicity.tex
\end{figure}

\paragraph{Perfectivity}
The boxplots in \reffig{explore_eng_perfectivity} illustrate the main effect of perfectivity on the acceptability judgments on the implicit object construction in English.

\begin{figure}[htb]
\caption{Effect of perfectivity on normalized acceptability judgments about object drop in English.}
\labfig{explore_eng_perfectivity}
    \input figures/ukwac_star_boxplot_perfectivity.tex
\end{figure}

\paragraph{Iterativity}
The boxplots in \reffig{explore_eng_iterativity} illustrate the main effect of iterativity on the acceptability judgments on the implicit object construction in English.

\begin{figure}[htb]
\caption{Effect of iterativity on normalized acceptability judgments about object drop in English.}
\labfig{explore_eng_iterativity}
    \input figures/ukwac_star_boxplot_iterativity.tex
\end{figure}

\paragraph{Manner specification}
The boxplots in \reffig{explore_eng_mannspec} illustrate the main effect of manner specification on the acceptability judgments on the implicit object construction in English.

\begin{figure}[htb]
\caption{Effect of manner specification on normalized acceptability judgments about object drop in English.}
\labfig{explore_eng_mannspec}
    \input figures/ukwac_star_boxplot_mannspec.tex
\end{figure}


\subsection{Joint effect of predictors} 

tre modelli misti con le tre regressioni (?)


\section{Italian results} \labsec{ita_judgresult}

\subsection{Semantic selectivity} 

The effect of semantic selectivity on the acceptability of the implicit object in Italian is quantified by means of a Pearson correlation between them. The results of this computation are visualized in \reffig{explore_ita_semsel_sps} for Resnik's SPS, in \reffig{explore_ita_semsel_cpisa} for Computational PISA, and in \reffig{explore_ita_semsel_bpisa} for Behavioral PISA.\\
What I observed in \refsec{eng_judgresult} about the correlations between the three models of semantic selectivity and human judgments about object drop in English still holds true, \textit{mutatis mutandis}, when considering the Italian data. First of all, it appears that Resnik's SPS is once again the worst-performing model among the three (with a staggeringly low, non-significant Pearson's $\rho$ of -0.055), Computational PISA makes the situation somewhat better but still not enough to be statistically significant (Pearson's $\rho$ = 0.223), and Behavioral PISA is quite a good model of semantic selectivity (Pearson's $\rho$ = 0.481, p value = 0.007).\\
Once again, this state of affairs mirrors the situation depicted in \refsec{evalMySPSs} (see \reftab{sps_correlmatrix_ita} in particular), where I made the case that Behavioral PISA, the human judgment-based benchmark model of semantic selectivity, correlates better with Computational PISA than with Resnik's SPS. Moreover, the non-significant correlation yielded by both Resnik's SPS and Computational PISA in Italian relative to the acceptability judgments on the implicit object construction mirrors the high correlation shown in \reftab{sps_correlmatrix_ita} between Resnik's SPS and Computational PISA. It would thus appear that the itWaC corpus has a stronger effect on the semantic similarity measures based on it than ukWaC has on the ones computed for English, as shown earlier in \refsec{evalMySPSs}.\\
Concluding, Behavioral PISA is a satisfactory predictor of object drop in Italian, with a correlation against human acceptability judgments on object drop comparable with the one obtained by Behavioral PISA in English (compare \labfig{explore_eng_semsel_bpisa} and \labfig{explore_ita_semsel_bpisa}). However, as is the case with English, Behavioral PISA is not able to fully predict the feasibility of object drop for a given transitive verb.

% % parlare dei singoli puntini rilevanti?

\begin{figure}[htb]
\caption{Correlation between semantic selectivity (Resnik's SPS) and normalized acceptability judgments on object drop in Italian.}
\labfig{explore_ita_semsel_sps}
    \input figures/itwac_preliminary_scatterplot_SPS.tex
\end{figure}

\begin{figure}[htb]
\caption{Correlation between semantic selectivity (Computational PISA) and normalized acceptability judgments on object drop in Italian.}
\labfig{explore_ita_semsel_cpisa}
    \input figures/itwac_preliminary_scatterplot_Computational_PISA.tex
\end{figure}

\begin{figure}[htb]
\caption{Correlation between semantic selectivity (Behavioral PISA) and normalized acceptability judgments on object drop in Italian.}
\labfig{explore_ita_semsel_bpisa}
    \input figures/itwac_preliminary_scatterplot_Behavioral_PISA.tex
\end{figure}


\subsection{Binary predictors} 

\paragraph{Telicity}
The boxplots in \reffig{explore_ita_telicity} illustrate the main effect of telicity on the acceptability judgments on the implicit object construction in Italian.

\begin{figure}[htb]
\caption{Effect of telicity on normalized acceptability judgments about object drop in Italian.}
\labfig{explore_ita_telicity}
    \input figures/itwac_star_boxplot_telicity.tex
\end{figure}

\paragraph{Perfectivity}
The boxplots in \reffig{explore_ita_perfectivity} illustrate the main effect of perfectivity on the acceptability judgments on the implicit object construction in Italian.

\begin{figure}[htb]
\caption{Effect of perfectivity on normalized acceptability judgments about object drop in Italian.}
\labfig{explore_ita_perfectivity}
    \input figures/itwac_star_boxplot_perfectivity.tex
\end{figure}

\paragraph{Iterativity}
The boxplots in \reffig{explore_ita_iterativity} illustrate the main effect of iterativity on the acceptability judgments on the implicit object construction in Italian.

\begin{figure}[htb]
\caption{Effect of iterativity on normalized acceptability judgments about object drop in Italian.}
\labfig{explore_ita_iterativity}
    \input figures/itwac_star_boxplot_iterativity.tex
\end{figure}

\paragraph{Manner specification}
The boxplots in \reffig{explore_ita_mannspec} illustrate the main effect of manner specification on the acceptability judgments on the implicit object construction in Italian.

\begin{figure}[htb]
\caption{Effect of manner specification on normalized acceptability judgments about object drop in Italian.}
\labfig{explore_ita_mannspec}
    \input figures/itwac_star_boxplot_mannspec.tex
\end{figure}


\subsection{Joint effect of predictors} 

tre modelli misti con le tre regressioni (?)



\section{Observations} \labsec{sumup_judgresult}

the take-home message of this chapter is that no predictor alone is decisive\\
confronto italiano-inglese

% dire che l'italiano SPS è consistentemente peggio dell'inglese (v. anche Model comparison SPS)