% \setchapterimage[6.5cm]{seaside}
\setchapterpreamble[u]{\margintoc}
\chapter{Conclusions and further remarks}
\labch{endchapter}

Conclusions

\section{Discussion of results} \labsec{end_discussion}

testo


\section{Conclusions} \labsec{end_conclusions}

testo


\section{Future directions} \labsec{end_future}

% parlare degli strumenti (consultare notebook_ideas.txt e appunti mPad) + Boland (2005) e gli strumenti come caso ibrido tra argomenti e aggiunti! e forse Resnik (1993)

% lingue tipologicamente diverse da inglese e italiano che marcano l'aspetto (perfectivity) in modo diverso, come il russo

% modellare corpus frequencies invece di grammaticality judgments (cite i.a. Manning 2002: 16), fare riferimento al capitolo "2.2.5.2 Expected Frequency and Relative Grammaticality" di Medina a p. 110 del pdf

% ampliare il set dei constraints (riferimento a hopper thompson 1980! v. capitolo 2)

% non-linear function nel modello! v. Medina p. 110 del pdf, nota 18

% rendere StOT simile a lmem()! io mi limito a minimizzare l'effetto-partecipanti normalizzando i giudizi, ma LMEM si occupa di controllare sia i verbi che i partecipanti

% un follow-up a riempimento di spazi per scoprire cosa è che viene omesso quando viene omesso un oggetto! e.g. "John was drinking _", per poi testare la recoverability con PISA + rispondere alle ipotesi del capitolo 2 sulla prototypicality + vedere se ha ragione Fillmore (citato in Cap 2 e Cap Model) ed effettivamente è un senso specifico del verbo (e uno specifico tipo di oggetto) a determinare object-droppability