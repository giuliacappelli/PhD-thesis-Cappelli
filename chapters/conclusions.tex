% \setchapterimage[6.5cm]{seaside}
\setchapterpreamble[u]{\margintoc}
\chapter{Conclusions and open questions}
\labch{conclusions}

\section{Final comments} \labsec{end_discussion}

\subsection{Recap of main findings}

I presented my models of the implicit indefinite object construction in English and in Italian in \refch{model}, together with a discussion of their performance and results. Here I will provide a short summary of the main findings of the two full models, namely, the five-predictor models I computed using Behavioral PISA (introduced in \refsec{behavPisa}) to quantify semantic selectivity, as explained in \refsec{intro_models}.\\
In general, the models perform comparably well, explaining almost half of the variance in the data (adjusted R\textsuperscript{2} is 0.468 for the English model and 0.455 for the Italian model, as reported in \refsec{intro_evaluation}). As I argued in \refch{model}, the better performance of the English model with respect to the Italian model may depend on semantic differences between the target verbs included in the behavioral experiments, and also on a more clear-cut role the predictors play in English than in Italian. These results, especially in the light of the fact that the full models improve on the performance of the reduced models (namely, Medina's three-predictor model and my own four-predictor model not considering manner specification\sidenote{As discussed in \refsec{intro_models}, the four-predictor models include Medina's three predictors and iterativity, while manner specification is only added in the full five-predictor models.}), are indeed encouraging. However, even the full models fall short of explaining all the variance in the data, demonstrating that there is still room for improvement. In \refsec{end_future}, I will propose some ideas to expand upon these models and improve their computation in future research.\\
Let us look more closely at the constraint re-rankings and subsequent grammaticality predictions of object drop in the two models. Both in English and in Italian, the probability of \textsc{*Int Arg} outranking \textsc{Telic End}\sidenote{Required to have grammatical implicit indefinite objects with telic verbs, as explained in \refch{medina} and \refch{model}.} varies strongly depending on Behavioral PISA, so that the curves described by the functions associated to this probability in the two languages are the steepest among all the curves associated to the re-ranking probabilities (as shown in \refsec{stot_full_parameters}). However, while in English the probability of \textsc{*Int Arg} outranking \textsc{Telic End} is directly proportional to semantic selectivity, in Italian the relation is one of inverse proportionality, for reasons discussed while commenting \reffig{ita_bpisa_telicity}.\\
Moreover, while in both languages the probability of \textsc{*Int Arg} outranking \textsc{Telic End} varies greatly depending on Behavioral PISA, there are differences with respect to the other predictors in the two languages. In particular, in English there is an interaction between the functions associated with the re-ranking probabilities of \textsc{Telic End} and \textsc{Perf Coda}, because telic imperfective verbs are more likely to drop their object than atelic perfective verbs for high Behavioral PISA values, while the opposite holds for Behavioral PISA scores lower than 0.8, approximately. In Italian, instead, there is an interaction between the function associated to the re-ranking probability of \textsc{Mann-Spec Arg} and the functions associated to the re-ranking probabilities of all the other constraints\sidenote{The interaction with \textsc{Non-Iter Arg} is trivial, because it happens when Behavioral PISA is 1, i.e., the maximum value.}. Thus, both models show a main effect of telicity on the probability that the object-less use of a transitive verb is considered grammatical, but the second most relevant factor in the model is perfectivity in English and manner specification in Italian.\\
In addition to the adjusted R\textsuperscript{2} values and the main role played by telicity, the two models are also comparable for:
\begin{itemize}
    \item the range of predicted object-dropping probabilities (30-100\% in English, 30-90\% in Italian);
    \item the relevance of semantic selectivity in determining the grammaticality of object drop (with re-ranking probabilities that are always directly proportional to Behavioral PISA, with the exception of \textsc{Telic End} in Italian);
    \item the fact that the predictors perform consistently with theoretical literature on object drop (refer to \refch{objectdrop}, \refch{factors}, and \refch{predictors}).
\end{itemize}

Indeed, in both models atelic imperfective iterative manner-specified verbs are the most likely to drop their object (between 80\% and 90\%), while telic perfective non-iterative manner-unspecified verbs are the least likely (between 30\% and 40\%). Moreover, atelic verbs are more likely to occur with implicit objects than telic verbs, imperfective verbs more than perfective verbs, iterative verbs more than non-iterative verbs, and manner-unspecified verbs more than manner-specified verbs, as expected.\\
Even though semantic selectivity plays an active role in both models, the range of predicted grammaticality across different input types is not the same in English and in Italian. Indeed, while it is comparable for low-Behavioral PISA verbs in the two languages (ranging from 30\% to 80\% in English and from 30\% to 90\% in Italian), it is much narrower and higher in English (between 90\% and 100\%) than in Italian (between 40\% and 90\%), as shown and discussed in \refsec{stot_full_predicted}.


\subsection{Comments on iterativity and manner specification}

In this dissertation, I modeled the implicit indefinite object construction following \posscite{Medina2007} steps. A major element of novelty I added is the inclusion of two novel constraints in the model, i.e., \textsc{Non-Iter Arg} and \textsc{Mann-Spec Arg} (refer to \refch{model}), which are based on the role played by iterativity and manner specification (refer to \refch{factors}), respectively, in facilitating indefinite object drop.\\
As I argued in \refsec{intro_evaluation}, the addition of these two new constraints proved to be beneficial to the performance of the model when applied both to English and to Italian data. Indeed, the full five-predictor models explain the variance in the data better than the three- and the four-predictor models regardless of the chosen measure of semantic selectivity (Resnik's SPS, Computational PISA, or Behavioral PISA). However, the four-predictor models (including iterativity in addition to Medina's telicity, perfectivity, and semantic selectivity) do not perform better than the three-predictor models, with basically identical adjusted R\textsuperscript{2} values in English and slightly smaller adjusted R\textsuperscript{2} values in Italian. Taken together, these results mean that iterativity alone is not a sufficient addition to Medina's model (rather, it makes the model needlessly more complicated, since it does not explain more variance in the data), but models including iterativity and manner specification together have a stronger explanatory power.\\
The lower performance of the models including iterativity without manner specification echoes observations drawn in \refsec{stot_full_parameters} relative to the probability of \textsc{*Int Arg} outranking \textsc{Non-Iter Arg}, that was shown to be very high both in a relative sense (since it is the highest among all the re-ranking probabilities) and in an absolute sense (92-100\% in English, 96-100\% in Italian). Since \textsc{Non-Iter Arg} is vacuously satisfied by iterative inputs, and varies almost imperceptibly according to semantic selectivity with non-iterative inputs (for which it is an active constraint), it stands to reason that it has no noticeable effect on the predicted grammaticality of object drop.\\
The same analysis would also explain the significant effect of the full models, where manner specification is also included among the predictors. In particular, in \refsec{intro_evaluation} I showed that the addition of manner specification determines a much stronger qualitative leap in the full models of Italian than in English, where the increase in the performance of the models is rather modest. Once again, these results are related to the probability of \textsc{*Int Arg} outranking the relevant constraint, i.e., \textsc{Mann-Spec Arg}. As shown in \refsec{stot_full_parameters}, the curve described by the function associated to this re-ranking probability is quite steep in Italian and it intersects all the other curves, while in English it is not steep at all and it has no interactions with the other curves. Thus, manner specification in Italian interacts in meaningful ways with semantic selectivity (as shown by the steepness of the curve) and the other binary predictors of object drop, making it an important factor in an expanded model of indefinite object drop. In English it has an effect too, but less evident.


\subsection{Comments on semantic selectivity}

In addition to the presence of additional constraints in the models, the other dimension of variation highlighted in \reftab{tab_mymodels} in \refsec{intro_models} is the measure used to quantify semantic selectivity in the models. In particular, I computed three families of models, each based on Resnik's SPS (as in Medina's original model), on Computational PISA, or on Behavioral PISA. In \refsec{intro_evaluation}, I provided adjusted R\textsuperscript{2} scores of each model in each family, showing that in English SPS-based models are the worst-performing, while PISA-based models are noticeably better (with Behavioral PISA being better than Computational PISA). In Italian, instead, Computational PISA-based models are the worst-performing, followed by SPS-based models and, lastly, by Behavioral PISA-based models.\\
In \refch{model}, I provided a possible explanation of these facts, together with the correlations between semantic selectivity and average Likert grammaticality ratings presented in \refsec{eng_judgresult_semsel} and \refsec{ita_judgresult_semsel}, by making reference to the way each measure of semantic selectivity is defined and computed (as detailed in \refsec{predictor_sps}). Let us consider the different performance of the three families of models in the light of \refsec{evalMySPSs}, where I evaluated the correlations between the three measures of semantic selectivity both in English and in Italian. I argued that the English facts (SPS-based models being worse than PISA-based models, and SPS correlating poorly with PISAs while Behavioral PISA and Computational PISA correlate well with each other) may depend on the nature of these measures, considering that both PISA measures are based on the computation of pairwise similarity scores (distributional cosine similarity for Computational PISA, Likert-scale human judgments of similarity for Behavioral PISA), while SPS suffers from all the problems of taxonomy-based measures, as discussed in \refsec{predictor_sps}. The Italian picture is different, since in this case Computational PISA-based models perform worse than SPS-based models. Interestingly, as shown in \refsec{ita_judgresult_semsel}, Computational PISA in Italian correlates very well with SPS (even better than with Behavioral PISA). I take this to mean that even after the manual cleansing I performed to purge any artifacts from the corpus data (recounted and motivated on \refpage{cleanthecorpus}), the itWaC corpus, upon which I based the computation of SPS and Computational PISA relative to Italian, has a stronger effect on the resulting scores than the ukWaC corpus, which I used to model the computational measures of semantic selectivity in English.\\
However, there may also be some undesirable side effect generated by the choice of ukWaC for English, given that I was able to reproduce Medina's findings relative to indefinite object drop in English with my three-predictor PISA-based models, but not with SPS, which is the measure she used (refer to \refsec{concl_medinacompare}). This may depend either on the corpus of choice or on the set of target verbs (or on both), but I am confident I can take the verbs off the suspect list because I made sure to include strictly transitive, as much as possible monosemous, verbs in my set (refer to \refsec{verbs}), while Medina used the same verbs included in \posscite{Resnik1993} original computation of SPS, a set also including verbs such as \textit{to do, to get, to have}. Thus, I conclude that I was not able to reproduce Medina's model using SPS because of the corpus I used. It would be possible to test this hypothesis by computing again Medina's model using her verb set and ukWaC, and my verb set and the corpus Resnik (and thus Medina) based his computation on. % If my hypothesis is correct, I would not replicate Medina's results in the former scenario, but I would do so in the latter. Of course, one may argue that the fault in the lack of replication may well lie in Medina's model itself, namely, either in her computation of SPS, or in artifacts determined by her choice of target verbs (which may be poor representatives of optionally transitive verbs in English). However, she based her analysis on Resnik's verb set and SPS scores, and it would be very improbable indeed that the inventor of SPS himself miscalculated his own model of object recoverability. The verbs would be a more likely culprit, but, on the other hand, I was able to replicate Medina's results with my PISA-based three-predictor models. How could Medina's model be wrong, but also consistent with a model of object drop (and, consequently, of the grammar of the English language) based on a different measure of semantic selectivity and different target verbs? Clearly, this scenario would be most unlikely.\\
To conclude, I observe that both in English and in Italian the best-performing models are based on Behavioral PISA. This result does not surprise at all, since this measure, being based on human similarity judgments, can be considered a benchmark model for semantic selectivity.


\subsection{Is (probabilistic) Optimality Theory the optimal choice?}

In \refch{modeltheory}, I provided several arguments in favor of the use of a probabilistic model of the implicit indefinite object construction, and, in particular, in favor of Stochastic Optimality Theory. 


% AL: Oltre alle considerazioni che trovi, metterei anche qualche riflessione sul ruolo di StOTcome modello delle grammatica alla luce delle tue analisi.  Della serie: dire perché vale la pena usare quello invece di altri modelli probabilistici o non.

% dire che qui uso medina e che in modeltheory ho parlato di modelli lineari e prob
% dire che i modelli lineari sono pessimi (citare quello Yankes e i miei altri esempi)
% confrontare Medina con ciascuno dei modelli prob che menziono

% However, as Kuhn (2002) puts
% it, a weighted-constraint theory has an "undesiderable property" for the
% linguist trying to model typologically realistic languages with linguistically motivated constraints. Indeed, in Harmonic Grammar the linguistic
% motivation of a set of constraints risks being trivial, since it is always
% possible to bend the weight set until the model accomodates all data,
% regardless of the constraints used in the model.

% Optimality Theory was then developed as a more restricted, linguistically motivated spawn of Harmonic Grammar, which replaces weighted % constraints with constraints ranked according to strict dominance

% A first attempt to bridge the gap between the resources of standard Optimality Theory and the need for finer-grained acceptability judgments
% was made by Keller (1997). In this work, the assumption of standard Optimality Theory that all non-optimal candidates are equally ungrammatical
% is dropped, in favor of an extended version of the framework where the
% grammaticality of each candidate is formulated in terms of a relative rank
% with respect to its competitors. [...] Moreover, even though graded grammaticality judgments are collected from native speakers and averaged to evaluate the (sub)optimality
% of candidates, these numerical values have only ordinal meaning. In
% other words, they are used to rank the candidates according to their
% grammaticality, but they have no other use. As a result, in Extended
% Optimality Theory the gradience of grammaticality actually stems from
% discrete, not continuous, values.

% The common feature underlying
% all these reformulations of Optimality Theory is that, by dropping the
% assumption of strict domination made in standard and Extended Optimality Theory, the gradient grammaticality of a candidate is defined as
% a function of the number and type of constraint re-rankings returning
% it as optimal. These models all allow for the re-ranking of constraints
% under an Optimality Theoretic lens, based on different algorithms and
% mathematical functions.
% How does this work in practice? For simplicity’s sake, in Section 4.2.4 I
% will focus only on the traditional version of Stochastic Optimality Theory
% (Boersma et al. 1997; Boersma and Hayes 2001), which is not only "the best
% motivated and most thoroughly probabilistic extension to Optimality
% Theory" (Manning 2003, p. 25), but also the one directly inspiring the
% model of indefinite object drop by Medina (2007).

% Wrapping up, these
% theories of grammar are unable to deal with candidate sets where each
% candidate is assigned a gradient grammaticality score on a continuous
% scale, yielding instead a single optimal candidate and several equally
% ungrammatical ones. Even the extended version of Optimality Theory by
% Keller (1997) (Section 4.2.2), although admitting degrees of suboptimality,
% still assumes strict domination among constraints, and makes use of
% grammaticality scores just to give the constraints an ordinal rank

% Stochastic Optimality Theory allows more than one candidate to be optimal at the same time by allowing constraints to "float" on the continuous
% scale, as if perturbed by numerical noise at the moment of evaluation


\section{Future directions} \labsec{end_future}

\subsection{Expanding the model} \labsec{expandingthemodel}

\paragraph{Additional predictors}

Among the linguistic factors facilitating indefinite object drop presented in \refch{factors}, I only picked five to serve as predictors in my models (detailed in \refch{predictors}), namely: semantic selectivity, telicity, perfectivity (all three from \posscite{Medina2007} original model), manner specification, and iterativity (two novel additions), for reasons detailed in \refsec{factorsofchoice}. The way these predictors are implemented in the (linear) Stochastic Optimality Theoretic models was explained in \refch{medina} relative to Medina's model and in \refch{model} relative to mine.\\
Future research may expand upon my models in the same way I expanded upon Medina's, namely, by introducing additional predictors in the model based on theoretical literature. A relevant area of interest, which I only brushed against by including iterativity (a broadly-intended pragmatic factor) in my model, is that of pragmatic and discourse factors (refer to \refsec{pragmaticfactors}). Since out-of-context utterances only happen in laboratory environments, research on pragmatic and discourse factors will provide much more ecological data to studies on indefinite object drop. However, this should not be intended as a potshot at models based on no-context stimuli, such as Medina's and the ones proposed in this dissertation. Indeed, given that the same semantic and aspectual factors determine indefinite object drop both in context-rich and in no-context utterances, it makes sense to model these factors first and to add contextual factors later on. Moreover, a word of caution is needed regarding the possible addition of pragmatics to experiment on indefinite object drop, since sufficient context may make virtually any object recoverable and, thus, any transitive verb acceptable when used intransitively. Thus, experiments including intra- and extra-linguistic contexts will have to be carefully calibrated in order to quantify the exact role of each type of context, and to avoid having context-external factors confound the experiment.\\
Given that indefinite object drop challenges prototypical transitivity, it would also be interesting to include in the model the neglected parameters described by \textcite{HopperThompson1980} (refer back to \reftab{ht1980_parameters} in \refsec{theory_transitivity}), in particular affirmation, mode, agency (strictly related to Agent affectedness, discussed on \refpage{affectedagent} and in \refsec{agentaffect}), and affectedness of the object (tackled in \refch{objectdrop}).

% PM: aggiungerei che i fattori pragmatici devono essere attentamente calibrati. In contesto, qualunque cosa può essere sottintesa purché inferibile. Ciò vale anche per gli argomenti che in esperimenti controllati risultano incancellabili.
% Quindi limiterei un po' il ruolo della pragmatica; è vero che potenzialmente può aggiungere qualcosa, ma come se ne misura l'effetto?

\paragraph{Corpus frequencies}

As shown in \textcite{Boersma2004, BoersmaHayes2001empirical}, Stochastic Optimality Theory can be used to model corpus data just as well as grammaticality judgments, namely, via the evaluation of constraints that get re-ranked along a continuous numerical scale (refer to \refch{modeltheory}). Rather than trivially duplicating the results I obtained and discussed in this dissertation, new models of corpus frequencies are sure to shed a different light on the implicit indefinite object construction. As I anticipated in \refsec{frequencyfail}, neither \textcite{Resnik1993, Resnik1996} nor \textcite{Medina2007} found a precise correlation between corpus frequencies and the gradient grammaticality judgments provided in behavioral experiments about implicit indefinite objects.\\
Indeed, linguistic research has long since shown that there is no clear-cut correspondence between ratings elicited from native speakers and corpus frequencies \parencite{manning2003probabilistic}. In particular, it is often the case that low-frequency utterances (or other linguistic items) receive mid-to-high acceptability judgments in behavioral experiments \parencite{KempenHarbusch2005, BermelKnittl2012, BaderHaussler2010, Boersma2004, KellerAsudeh2002}. There is also no strict relation between the relative grammaticality of a linguistic structure with respect to another and their relative corpus frequencies, since, for instance, \textcite[315-316]{BaderHaussler2010} report that they found no pairs of syntactic structures in their study where a member of the pair was judged as more grammatical than the other but occurred with a smaller frequency in the corpus, while \textcite{Boersma2004} argues in favor of the opposite. Moreover, \textcite{BaderHaussler2010} experimental results show both a "ceiling mismatch"\sidenote{The authors also observe that this is not a measurement artifact due to the use of a capped scale, such as binary or 7-point Likert ratings, because it is also found with Magnitude Estimation ratings, which are open-ended both at the top and at the bottom.} (meaning that two syntactic structures may be judged as maximally grammatical, but occur with different frequencies in the corpus) and a "floor mismatch" (meaning that two syntactic structures may never or almost-never occur in the corpus, but receive different acceptability judgments).\\
A common worry about linguistic research based on corpus material is that frequencies are less reliable than human judgments because there is no way to control language production as one controls an experimental design. This line of reasoning would surely curb easy enthusiasm about the replication of the current study to model corpus frequencies of indefinite object drop, if \textcite{Steube2008, Schutze2016} did not observe that acceptability ratings are too "contaminated by performance factors", that is to say, biased by other tasks the raters perform in addition to the one they are explicitly asked to carry out (e.g., they judge the similarity between the target sentence and the one they consider its "ideal delivery" paraphrase). Thus, if linguistics gladly relies on acceptability judgments (and, oftentimes, the results of one's own introspection), provided they are based on a rigorous experimental design, there should be no qualms about modeling corpus frequencies, provided they are interpreted in the light of the factors possibly influencing them. In general, given that no experimental method is error-free, it is good practice to compare the results obtained with different methods. In the specific case of studies on indefinite object drop, there may be a trade-off between the analysis of easily computable\sidenote{Provided the corpus is annotated in such a way as to make data extraction easy, of course.} frequencies extracted from non-manipulable\sidenote{Also, possibly under-representative of the language one intends to study, given that even in corpora that are not genre-specific it is difficult to obtain complete coverage of language uses and contexts.} corpus utterances, and the analysis of acceptability judgments provided by human subjects on easily manipulable experimental stimuli, even though these judgments stem from often unfathomable individual processes going on in the mind of each subject.\\
Modeling corpus frequencies of indefinite null objects using the very same model(s) defined in this dissertation may present additional challenges if compared to modeling acceptability ratings, since it is impossible to manipulate aspectual and discourse factors in a corpus study as in a behavioral experiment. However, the possible absence (or very low frequency) of a given object-less verb in a given aspect may well be considered an interesting, modelable datum in itself, provided one adjusts the model to account for such findings. Alternatively, it would be possible to design a production experiment to design an \textit{ad-hoc} corpus to model the frequency of indefinite null objects in controlled speech or writing. It is also important to note that it would be possible, if not even easy, to include discourse and world-knowledge context (somewhat ancillary to semantics and aspectual factors in this dissertation) in a model of object drop based on frequencies extracted from a large corpus, given that these null objects appear in sentences which are part of larger documents with explicit context information. Moreover, a corpus study of object drop may provide an answer to a question foreshadowed by \textcite{KempenHarbusch2005, Medina2007} (refer to \refsec{frequencyfail}), namely, whether a "production threshold" exists blocking mid-to-low grammaticality structures from ever being uttered and, if so, which numerical value has to be assigned to this threshold.

% PM: aggiungerei che, siccome nessun metodo sperimentale è privo di intrinseci limiti, è buona prassi confrontare i risultati di diversi metodi.
% Nel caso specifico, si può ipotizzare un trade-off fra la rigidità dei contesti fissati nei corpora, e l'inverificabile libertà individuale nel ricostruire mentalmente i possibili contesti d'uso in relazione agli stimoli.

% AL: Il problema non è solo quello. C’è la distribuzione zipfiana dei dati anche la difficile valutazione della rappresentatività dei dati. Last but not least i problemi della loro estrazione

\paragraph{Other implicit complements of verbs}
Direct object of optionally transitive verbs are far from being the only NP complements of verbs participating in syntactic omissions. For instance, the literature mentions:

\begin{itemize}
    \item Agents of passives, as in \textit{The ship was sunk $\varnothing$\textsubscript{Agent}} \parencite{BhattPancheva2017implicit, Lasersohn1993, RuppenhoferMichaelis2014};
    \item Source \parencite{Gillon2006english}, Goal \parencite{Lasersohn1993, RuppenhoferMichaelis2014}, and Path \parencite{recanati2002unarticulated} locative phrases occurring with motion verbs\sidenote{Interestingly, \textcite[9-12]{Gillon2006english} and \textcite[333]{ruppenhofer2011search} observe that in some pairs of near-synonym verbs, such as \textit{to leave, to vacate} and \textit{to arrive, to reach}, only one member of the pair allows for the omission of the locative phrase. This is consistent with the literature on the role of manner specification in argument omission (refer to \refsec{mannerspec}).}, as in \textit{Bill left $\varnothing$\textsubscript{Source}}, \textit{Hilary arrived $\varnothing$\textsubscript{Goal}}, and  \textit{The cow jumped over $\varnothing$\textsubscript{Path}};
    \item Themes of reflexive (\textit{Peter shaved (himself)}) and reciprocal (\textit{Mary and Peter divorced (from each other)}) predicates \parencite{NemethEniko2014};
    \item Recipients of three-argument verbs, as in \textit{The mayor donated \$300 $\varnothing$\textsubscript{Recipient}} \parencite{ruppenhofer2005regularities};
    \item Instruments, as in \textit{The executioner beheaded the prisoner $\varnothing$\textsubscript{Instrument}} \parencite{KoenigEtAl2002, KoenigEtAl2003, KoenigEtAl2007, RissmanEtAl2015, RissmanRawlins2017, Rissman2010}.
\end{itemize}

Among all these \textit{syntactically} optional complements of verbs, Instruments stand out because they can also be \textit{semantically} optional. Indeed, \textcite{KoenigEtAl2002, KoenigEtAl2003, KoenigEtAl2007} divided Instrument-taking verbs into two classes, i.e., the Require-Instrument class (\textit{to chop, to slice, to write}) and the Allow-Instrument class (\textit{to eat, to break, to open}). In \textcite{CappelliLenciPISA}, I computed Computational PISA scores of Instrument-taking English verbs (together with transitive verbs, as discussed in \refsec{compuPisa}), showing that this measure of semantic selectivity can reliably tell apart Require- and Allow-Instrument verbs. I argue that this is a promising starting point in a possible computational model of the factors regulating the syntactic optionality of Instruments, given the insight this method provided in the study of indefinite object drop.\\
Modeling Instruments, as well as the other implicit complements listed in this Section, will provide useful information to further theoretical and experimental research on syntactic optionality.

\paragraph{Indefinite object drop diachronically}
As argued in \refsec{frequencyfail}, with reference to \textcite{Goldberg2001, Goldberg2005a, Lorenzetti2008, Glass2020}, verbs appearing in generic contexts with a habitual interpretation (e.g., \textit{Pat drinks; Pat smokes; Chris sings; Sam bakes}, from \textcite[518]{Goldberg2001}) are likely to participate in the implicit indefinite object construction, due to Goldberg's principle of Omission under Low Discourse Prominence. Diachronically, the frequent use of transitive verbs in such contexts probably led to the grammaticalization of their intransitive use in episodic contexts as well, often with a specialized meaning (e.g. 'to drink alcohol' in \textit{Pat drinks}, 'to bake pastries' in \textit{Sam bakes}).\\
A model of indefinite object drop in historical and contemporary texts (a gap in the literature first observed by \textcite{Goldberg2001}) would substantiate this hypothesis and shed some more light on the mechanisms regulating the role of semantic and aspectual predictors in addition to discourse factors. Moreover, diachronic change also affects semantic selectivity (which, as discussed in \refch{objectdrop}, \refch{factors}, and \refch{predictors} is a major predictor of indefinite object drop) and other facets of verb meaning. For instance, verbs may undergo semantic changes expanding the range of their meaning (e.g., Vulgar Latin \textit{*adripare} 'to reach the shore' gave rise to Italian \textit{arrivare} 'to arrive'), shifting it from a concrete to a metaphorical interpretation (e.g., \textit{to broadcast} originally meant 'to cast seeds widely' on a field, while the rise of communication technologies in the 20th century shifted its meaning to 'spread a message or news widely'), or restricting it (e.g., Latin \textit{cubare} 'to lie, to rest' became Italian \textit{covare} 'to brood', referring to the lying act performed by egg-laying animals to nurse their eggs).\\
Several corpora of English and Italian are available for a diachronic study on indefinite object drop, each focusing on different text types within different time spans. Among the diachronic corpora of English\sidenote{Refer to \textcite{hilpert2016quantitative} for an introduction to quantitative approaches to diachronic corpus linguistics mentioning several corpora of English.}, relevant ones to inquire about null objects may be:
\begin{itemize}
    \item the Helsinki Corpus of English Texts \parencite{rissanen1993helsinki}, spanning over Old (V-XII centuries) to Early Modern (late 15th - late 17th centuries) English, and covering many different genres (such as chronicles, handbooks, laws, and Bible excerpts);
    \item the Corpus of Late Modern English Texts \parencite{deSmet2005corpus, deSmet2015corpus}, covering public domain British English texts from 1710 to 1920;
    \item the Corpus of Historical American English \parencite{davies2010corpus, davies2012expanding}, recently purged of inconsistent lemmas and malformed tokens \parencite{alatrash2020ccoha}, a large-scale (around 400 million words) corpus covering different genres (newspapers, fiction and non-fiction books, magazines) from 1810 to 2009.
\end{itemize}

As for Italian, relevant diachronic corpora may be:
\begin{itemize}
    \item DiaCORIS \parencite{onelli2006diacoris}, a 100-million-word corpus of texts written between 1861 (year of the National Unification) and 1945 covering genres such as newspapers, fiction, and academic prose;
    \item the MIDIA corpus \parencite{gaeta2013midia, iacobini2014midia}, a 7-million-word corpus of documents written between the 13th and the 20th centuries;
    \item the OVI corpus \parencite{ovi2005corpus}, a half-million word corpus of texts from the 12th to the 14th centuries;
    \item a diachronic corpus of newspaper articles published on "L'Unit\`{a}", the official newspaper of the Italian Communist Party from 1924 to the dissolution of the Party in 1991, published between 1924 and 2015.
\end{itemize}

In theory, the wider the time span covered by a given diachronic corpus, the better. A corpus ranging over several centuries of written language would indeed provide a broad perspective on the possible grammaticalization of null objects outside habitual contexts. However, it may also be the case that changes in grammar happened much faster in the last century, when distant communication became possible, literacy was not an upper-class privilege anymore, and, in the last 30 years or so, English became the main language of the internet. As for Italian, \textcite{basile2020diachronic} observe that deep changes occurred in this language during the second half of the 20th century. Thus, it is possible that use-dependent pressures towards the grammaticalization of null objects are more evident in corpora focusing on the last century, than on previous time periods. Moreover, subtle changes of this kind are surely more frequent and observable in corpora based on spoken language, or language written to be read shortly after (such as the one used in newspapers and other mass media). Thus, both broad diachronic corpora and 20th-century corpora may be of use to understand the history of indefinite object drop.

% PM: ottima prospettiva di ricerca; qui completerei il discorso indicando su quali corpora inglese e italiani si potrebbe condurre una simile ricerca diacronica, e con quali limiti eventuali dovuti al tipo di testi.
% Quest'ultima cautela potrebbe semplicemente essere espressa come un fatto da tenere in considerazione.

% AL: Potresti menzionare anche il fatto che i. Diacronia ca,bua anche il senso dei verbi e a che la loro se,antic selectivity. Pensa al famoso caso di adripare che significava andare su un’altra riv del fiume e poi ora significa arrivare in qualsiasi luogo. I processi di restringimento o allargamento semantico possono produrre effetti sulla semantic selectivity e dunque sull’omissione dell’oggetto

\paragraph{Typologically different languages}
In this dissertation, I modeled the implicit indefinite object construction in English and Italian, two typologically close languages. As discussed in \refch{model}, several differences between the two emerged with respect to their licensing of indefinite null objects, meaning that this phenomenon depends on much finer-grained aspects than what typology alone would warrant. Nevertheless, a theory of grammar should not be a theory of English and English-like languages alone, and therefore a comprehensive model of indefinite object drop should consider a variety of typologically different languages.\\
As noted by \textcite[134]{Jackendoff2003}, languages such as Korean and Japanese (to which we may add Chinese) allow for null arguments more easily than English, so that they would pose "no justiﬁcation for distinguishing between obligatorily and optionally expressed semantic arguments". However, in the same paragraph he also argues in favor of the distinction between definite and indefinite null objects being a fully idiosyncratic lexical property of verbs or, at most, of semantic verb classes, a position which I argued against throughout \refch{objectdrop} and \refch{factors}. Thus, it is not to be excluded that languages such as Korean, Japanese, and Chinese may show different degrees of acceptability of indefinite object drop with different optionally transitive verbs, even if they are free in their Topic-drop-based licensing of definite null objects (just like English and typologically similar languages are, as argued on \refpage{recipes}). Another aspect differentiating these languages from languages such as English and Italian, with respect to aspects playing a role in object drop, is their treatment of non-culminating accomplishments. Indeed, while in English the sentence \textit{*I burned it but it didn't burn} is utterly ungrammatical due to being contradictory, its Japanese equivalent (\textit{moyashita keredo moenakatta}, as reported in \textcite[236]{radden2003metonymic}) is grammatical because the verb \textit{moyasu} 'to burn' is less focused on the result than its English counterpart \textemdash it is, thus, a non-culminating accomplishment. The existence of such verbs made \textcite{ikegami1991language} distinguish between DO-languages such as English, focusing on the Agent, and BECOME-languages such as Japanese, focusing on the process. Indeed, given the considerations provided in \refsec{theory_incorporation} relative to indefinite object drop as a mechanism driven by the need to focus on the activity rather than on its effects on the Patient, it stands to reason that BECOME-languages should allow object drop more often and in a wider variety of contexts than DO-languages.\\
Another typologically different family, namely, Slavic languages, may shed light on the role played by grammatical aspect in the implicit indefinite object construction. As mentioned in \refsec{perfectivity}, simplifying a very long tradition of studies in a way that will surely disgruntle many of those who fostered research in this area, in Slavic languages perfectivity is embedded in the lexicon rather than being expressed morphologically (as in English and Italian). To be more precise, in Slavic languages the opposition between so-called perfective and imperfective verbs actually derives from the encoding (or lack thereof) of telicity in the verb \parencite{bertinetto2012diachronic, bertinetto-delfitto2000aspect, bertinetto2001frequent}. In a diachronic perspective, discussed in \textcite{bertinetto2012diachronic} relative to Russian, the loss of the overt aspectual markers in the passage between Old Slavonic to (Northern) Slavic languages gave rise to a syncretic system merging lexical aspect and grammatical aspect. The opposition between prefixed and simple verbs in Russian is interpreted as "unmistakable evidence" of the original distinction being one of lexical, not grammatical, aspect. Crucially, since so-called imperfective Slavic verbs can be used in perfective contexts, and given that so-called perfective verbs are always ungrammatical with null objects \parencite{sopata2016null, TsimpliPapadopoulou2006}, experiments relative to indefinite object drop in Slavic languages (be they corpus-based or judgment-based) should only focus on the realization of implicit objects with imperfective transitive verbs. I take this state of affairs to mean that \textsc{Perf Coda} acts as a hard constraint in Slavic languages, being always re-ranked above \textsc{*Int Arg} for perfective inputs (refer to \refch{medina} and \refch{model}), instead of being a soft, re-rankable constraint as it is in English and Italian. Indeed, as discussed in \refsec{telperftense}, in these two languages telicity, perfectivity and tense are intertwined, so that the interpretation of one factor partially depends on the others. This explains why in my models telicity and (secondarily) perfectivity both play a gradient role in favoring object drop, depending on each verb's semantic selectivity, despite the behavioral experiments being carefully designed to isolate the effect of each factor at play. Based on previous considerations, I hypothesize that a model of indefinite object drop in Slavic languages would paint quite a different picture.

% PM: aggiungici il cinese; poi ne esistono tante altre, ma per questo tipo di indagine bisogna andare su lingue con ampia disponibilità di corpora.
% Comunque sia, il discorso che fai è incompleto; lo puoi completare accennando al tema dei così detti 'non-culminating telics'; nelle lingue qui citate, e in tante altre, il valore telico dei predicati è assai labile.
% Si può dire per es.:
% I burned it but it didn't burn
% (che era il titolo di una articolo sul giapponese)
% perché 'bruciare X' non significa necessariamente 'consumarlo col fuoco', ma può significare 'appiccargli il fuoco'. L'entrata lessicale è la stessa, la sua interpretazione telica varia a seconda del contesto.

% PM: te lo lascio dire così, ma è una c....ta.
% Anzi no, non te lo lascio proprio dire. 
% (a lezione dormivi, di' la verità!)
% Il problema qui non è la perfettività in quanto tale, ma la telicità necessariamente soddisfatta (in quanto lessicalmente espressa). La perfettività DISCENDE dalla telicità incorporata nel predicato.
% Difatti, i verbi slavi 'imperfettivi' possono tranquillamente essere usati in contesti perfettivi. 
% Quindi vedi bene che quasi tutti quelli che scrivono su queste cose ripetono scemenze, che si propagano di citazione in citazione.
% Maledetti!!!!

% PM: per l'appunto! Siccome nelle liingue slave l'integrazione di azionalità e aspetto è ancora più tenace, perché lessicalmente espressa (almeno per i verbi 'perfettivi'), ci si deve aspettare un diverso comportamente.
% Anzi, guarda, per quanto riguarda i 'perfettivi' transitivi è perfettamente inutile la verifica sperimentale, perché senza oggetto espresso le frasi sono banalmente inaccettabili. Ci si può solo concentrare sugli 'imperfettivi' transitivi.
% Questo almeno dillo, se no ... calci negli stinchi!

% vecchia frase mia: Should experimental evidence confirm the claim that Slavic languages do not allow for object drop with perfective verbs, this would mean [hard constraint]


\subsection{Different math}

In this dissertation I followed \textcite{Medina2007} in providing a Stochastic Optimality Theoretic model of indefinite object drop (see \refch{medina}) where the binary predictors described in \refch{predictors} are used to define four faithfulness constraints re-ranking with respect to \textsc{*Int Arg} (a markedness constraint). Semantic selectivity, modeled along a continuous numerical scale, cannot give rise to a binary constraint itself. Instead, Medina implements it in the model by defining the probability of each faithfulness constraint re-ranking with respect to \textsc{*Int Arg} as a (linear) function of the semantic selectivity of the input verb, deviating from the Stochastic Optimality Theoretic norm of associating fixed normal curves to constraints (refer to \refsec{stochot}). However, as \textcite[110]{Medina2007} herself comments, there is no compelling reason why these re-ranking functions should be necessarily \textit{linear} functions. Indeed, she argues that linear functions are "a reasonable place to begin to explore the relative contribution of
Semantic Selectivity to the implicit object construction", and I followed in her steps to obtain models comparable to hers. Future research on indefinite object drop may benefit from employing non-linear functions, defining a more complex algorithm than the one used here to determine the best function and its parameters.\\
Going back to linear Stochastic Optimality Theoretic models of object drop, in \refsec{concl_lmem} I commented on the differences between them and linear mixed-effects models, which are linear regression models including both fixed and random effects in the computation. Mixed models, by their very nature, are able to account both for the effect of the predictors of object drop on the grammaticality of indefinite null objects (the fixed effects), and for the effect of the source of random variability in the data, i.e., the target verbs and the participants to the experiment (the aptly-named random effects). Medina's model and my own, instead, are more like classic linear regression model in that they only account for fixed effects. I minimized any effect the human participants may have had on the results by modeling their normalized ratings (refer to \refsec{likert_preprocessing}), but this pre-processing adaptation of the Likert ratings is more of a quick fix than the kind of solid method I endorse for future research. Indeed, ideally the model should take raw ratings as input, and not only account for the different use the participants made of the Likert scale, but also quantify the amount of variance in the data depending on the participants alone. The same goes for random effects depending on the target verbs, which my models are not able to compute.

\subsection{A follow-up on recoverability and prototypicality}

In \refsec{whichobjects}, I argued, with reference to the literature, that indefinite null objects refer to the prototypical Patients of a given transitive verb, as recovered by speakers via world knowledge. However, this prototypicality is not to be intended as a monolith. Rather, it depends on extra- and intra-linguistic context, as it is possible to argue based on \posscite{Rice1988} examples in \ref{rice_concl}. In \ref{rice1_concl}, the act of smoking is intended to refer to cigarettes, because they are the most common object of smoking in contemporary Western society, but different context (such as a mention to olden times, or a Middle-East setting) may induce a reading where the omitted object refers to a pipe or a waterpipe. In \ref{rice2_concl}, the act of drinking is linked to alcohol assumption for reasons made clear in \refch{objectdrop} and \refsec{agentaffect}, but it would necessarily refer to some other prototype were the subject a toddler or a teetotaler, let alone a non-human participant. Similarly, John may be understood to drive a bike in \ref{rice3_concl} and to read a newspaper in \ref{rice4_concl}, provided slight differences in the available context (e.g., a downtown location to drive to, or a different reading time).

\ex. \label{rice_concl} \a. \label{rice1_concl} John smokes (cigarettes / *Marlboros / *a pipe / *SMOKING MATERIALS).
\b. \label{rice2_concl} John drinks (alcohol / *gin / *water / *coffee / *LIQUIDS).
\c. \label{rice3_concl} When he goes to Boston, John drives (a car / *a Toyota / *a motorcycle / *A VEHICLE).
\d. \label{rice4_concl} Each afternoon, John reads (a book / *Ulysses / *the newspaper / *PRINTED MATTER).

Therefore, possibly enriching some additional models I envisioned in \refsec{expandingthemodel}, it may be useful to design an experiment targeted at the prototypicality\sidenote{This task tackles a different problem than the one this thesis focused on (i.e., modeling the grammaticality of object-less transitive verbs).} intrinsic to object recoverability. I would imagine a cloze-test experiment where subjects have to fill in the gap in sentences such as \textit{John smokes \_\_\_}, manipulating context as to have no-context sentences, common-sense contexts, and uncommon contexts. I hypothesise that there would be much greater agreement between participants relative to the fillers of common-context stimuli and no-context stimuli (where the context is inherently provided via world knowledge), than the agreement relative to uncommon-context stimuli (where it is difficult to imagine prototypicality). % I suspect a reaction-time experiment relative to the acceptability of such object-less stimuli would yield results consistent with these expectations.

% AL: Questo i sembra un problema diverso da quello che hai affrontato nella tesi. Ti occupi dell’a ettabilita di frasi con oggetto omesso e non di quale oggetto viene tipicamente recuperato. Ok come prospetttiva di ricerca, ma solo se dici che è un task di tipo diverso 