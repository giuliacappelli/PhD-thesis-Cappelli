% \setchapterimage[6.5cm]{seaside}
\setchapterpreamble[u]{\margintoc}
\chapter{Conclusions and further remarks}
\labch{conclusions}

% Conclusions

\section{Discussion of results} \labsec{end_discussion}

\subsection{Feasibility of these models}

testo

\subsection{Indefinite object drop cross-linguistically}

testo

\subsection{Relevance of the two new constraints}

testo (voleva AL)

\subsection{Comments on PISA models of semantic selectivity}

testo (voleva AL)


\section{Future directions} \labsec{end_future}


\subsection{Expanding the model} \labsec{expandingthemodel}

\paragraph{Additional predictors}

Among the linguistic factors facilitating indefinite object drop that I presented in \refch{factors}, I only included five as predictors in my models (detailed in \refch{predictors}). These are semantic selectivity, telicity, perfectivity (all three from \posscite{Medina2007} original model), manner specification, and iterativity (two novel additions), for reasons detailed in \refsec{factorsofchoice}. The way these predictors are implemented in the (linear) Stochastic Optimality Theoretic models was explained in \refch{medina} relative to Medina's model and in \refch{model} relative to mine.\\
Future research may expand upon my models in the same way I expanded upon Medina's, namely, by introducing additional predictors in the model based on theoretical literature. A relevant area of interest, which I only brushed against by including iterativity (a broadly-intended pragmatic factor) in my model, is that of pragmatic and discourse factors (refer to \refsec{pragmaticfactors}). Since context-free utterances only happen in laboratory environments, research on pragmatic factors and the influence of extra-linguistic context will provide much more ecological data to studies on indefinite object drop. However, this should not be intended as a potshot at models based on no-context stimuli, such as Medina's and the ones I proposed in this dissertation. Indeed, given that the same semantic and aspectual factors determine indefinite object drop both in context-rich and in no-context utterances, it makes sense to model these factors first and to add contextual factors later on.\\
Given that indefinite object drop challenges prototypical transitivity, it would also be interesting to include in the model the neglected parameters described by \textcite{HopperThompson1980} (refer back to \reftab{ht1980_parameters} in \refsec{theory_transitivity}), in particular affirmation, mode, agency (strictly related to Agent affectedness, discussed on \refpage{affectedagent} and in \refsec{agentaffect}), and affectedness of the object (tackled in \refch{objectdrop}).

\paragraph{Corpus frequencies}

As shown in \textcite{Boersma2004, BoersmaHayes2001empirical}, Stochastic Optimality Theory can be used to model corpus frequencies just as well as grammaticality judgments, namely, via the evaluation of constraints that get re-ranked along a continuous numerical scale (refer to \refch{modeltheory}). Rather than trivially duplicating the results I obtained and discussed in this dissertation, new models of corpus frequencies are sure to shed a different light on the indefinite implicit object construction. As I anticipated in \refsec{frequencyfail}, neither \textcite{Resnik1993, Resnik1996} nor \textcite{Medina2007} found a precise correlation between corpus frequencies and gradient grammaticality judgments provided in behavioral experiments about indefinite implicit objects.\\
Indeed, linguistic research has long since shown that there is no clear-cut correspondence between ratings elicited from native speakers and corpus frequencies \parencite{manning2003probabilistic}. In particular, it is often the case that low-frequency utterances (or other linguistic items) receive mid-to-high acceptability judgments in behavioral experiments \parencite{KempenHarbusch2005, BermelKnittl2012, BaderHaussler2010, Boersma2004, KellerAsudeh2002}. There is also no strict relation between the relative grammaticality of a linguistic structure with respect to another and their relative corpus frequencies, since, for instance, \textcite[315-316]{BaderHaussler2010} report that they found no pairs of syntactic structures in their study where a member of the pair was judged as more grammatical than the other but occurred with a smaller frequency in the corpus, while \textcite{Boersma2004} argues in favor of the opposite. Moreover, \textcite{BaderHaussler2010} experimental results show both a "ceiling mismatch"\sidenote{The authors also observe that this is not a measurement artifact due to the use of a capped scale, such as binary or 7-point Likert ratings, because it is also found with Magnitude Estimation ratings, which are open-ended both at the top and at the bottom.} (meaning that two syntactic structures may be judged as maximally grammatical, but occur with different frequencies in the corpus) and a "floor mismatch" (meaning that two syntactic structures may never or almost-never occur in the corpus, but receive different acceptability judgments).\\
A common worry about linguistic research based on corpus material is that frequencies are less reliable than human judgments because there is no way to control language production as one controls an experimental design. This line of reasoning would surely curb easy enthusiasm about the replication of the current study to model corpus frequencies of indefinite object drop, if \textcite{Steube2008, Schutze2016} did not observe that acceptability ratings are too "contaminated by performance factors", that is to say, biased by other tasks the raters perform in addition to the one they are explicitly asked to carry out (e.g., they judge the similarity between the target sentence and the one they consider its "ideal delivery" paraphrase). Thus, if linguistics gladly relies on acceptability judgments (and, oftentimes, the results of one's own introspection), provided they are based on a rigorous experimental design, there should be no qualms about modeling corpus frequencies, provided they are interpreted in the light of the factors possibly influencing them.\\
Modeling corpus frequencies of indefinite null objects using the very same model(s) I defined in this dissertation may present additional challenges if compared to modeling acceptability ratings, since it is impossible to manipulate aspectual and discourse factors in a corpus study as in a behavioral experiment. However, the possible absence (or very low frequency) of a given object-less verb in a given aspect may well be considered an interesting, modelable datum in itself, provided one adjusts the model to account for such findings. Alternatively, it would be possible to design a production experiment to design an \textit{ad-hoc} corpus to model the frequency of indefinite null objects in controlled speech or writing. It is also important to note that it would be possible, if not even easy, to include discourse and world-knowledge context (somewhat ancillary to semantics and aspectual factors in this dissertation) in a model of object drop based on frequencies extracted from a large corpus, given that these null objects appear in sentences which are part of larger documents with explicit context information. Moreover, a corpus study of object drop may provide an answer to a question foreshadowed by \textcite{KempenHarbusch2005, Medina2007} (refer to \refsec{frequencyfail}), namely, whether a "production threshold" exists blocking mid-to-low grammaticality structures from ever being uttered and, if so, which numerical value has to be assigned to this threshold.


\paragraph{Other implicit complements of verbs}
Direct object of optionally transitive verbs are far from being the only NP complements of verbs participating in syntactic omissions. For instance, literature mentions:

\begin{itemize}
    \item Agents of passives, as in \textit{The ship was sunk $\varnothing$\textsubscript{Agent}} \parencite{BhattPancheva2017implicit, Lasersohn1993, RuppenhoferMichaelis2014};
    \item Source \parencite{Gillon2006english}, Goal \parencite{Lasersohn1993, RuppenhoferMichaelis2014}, and Path \parencite{recanati2002unarticulated} locative phrases occurring with motion verbs\sidenote{Interestingly, \textcite[9-12]{Gillon2006english} and \textcite[333]{ruppenhofer2011search} observe that in some pairs of near-synonym verbs, such as \textit{to leave, to vacate} and \textit{to arrive, to reach}, only one member of the pair allows for the omission of the locative phrase. This is consistent with the literature on the role of manner specification in argument omission (refer to \refsec{mannerspec}).}, as in \textit{Bill left $\varnothing$\textsubscript{Source}}, \textit{Hilary arrived $\varnothing$\textsubscript{Goal}}, and  \textit{The cow jumped over $\varnothing$\textsubscript{Path}};
    \item Themes of reflexive (\textit{Peter shaved (himself)}) and reciprocal (\textit{Mary and Peter divorced (from each other)}) predicates \parencite{NemethEniko2014};
    \item Recipients of three-argument verbs, as in \textit{The mayor donated \$300 $\varnothing$\textsubscript{Recipient}} \parencite{ruppenhofer2005regularities};
    \item Instruments, as in \textit{The executioner beheaded the prisoner $\varnothing$\textsubscript{Instrument}} \parencite{KoenigEtAl2002, KoenigEtAl2003, KoenigEtAl2007, RissmanEtAl2015, RissmanRawlins2017, Rissman2010}.
\end{itemize}

Among all these \textit{syntactically} optional complements of verbs, Instruments stand out because they can also be \textit{semantically} optional. Indeed, \textcite{KoenigEtAl2002, KoenigEtAl2003, KoenigEtAl2007} divided Instrument-taking verbs into two classes, i.e., the Require-Instrument class (\textit{to chop, to slice, to write}) and the Allow-Instrument class (\textit{to eat, to break, to open}). In \textcite{CappelliLenciPISA}, I computed Computational PISA scores of Instrument-taking English verbs (together with transitive verbs, as discussed in \refsec{compuPisa}), showing that this measure of semantic selectivity can reliably tell apart Require- and Allow-Instrument verbs. I argue that this is a promising starting point in a possible computational model of the factors regulating the syntactic optionality of Instruments, given the insight this method provided in the study of indefinite object drop.\\
Modeling Instruments, as well as the other implicit complements listed in this Section, will provide useful information to further theoretical and experimental research on syntactic optionality.

\paragraph{Indefinite object drop diachronically}
As argued in \refsec{frequencyfail}, with reference to \textcite{Goldberg2001, Goldberg2005a, Lorenzetti2008, Glass2020}, verbs appearing in generic contexts with a habitual interpretation (e.g., \textit{Pat drinks; Pat smokes; Chris sings; Sam bakes}, from \textcite[518]{Goldberg2001}) are likely to participate in the indefinite implicit object construction, due to Goldberg's principle of Omission under Low Discourse Prominence. Diachronically, the frequent use of transitive verbs in such contexts probably led to the grammaticalization of their intransitive use in episodic contexts as well, often with a specialized meaning (e.g. 'to drink alcohol' in \textit{Pat drinks}, 'to bake pastries' in \textit{Sam bakes}).\\
A model of indefinite object drop in historical and contemporary texts (a gap in the literature first observed by \textcite{Goldberg2001}) would substantiate this hypothesis and shed some more light on the mechanisms regulating the role of semantic and aspectual predictors in addition to discourse factors.

\paragraph{Typologically different languages}
In this dissertation, I modeled the indefinite implicit object construction in English and Italian, two typologically close languages. As discussed in \refch{model}, several differences between the two emerged with respect to their licensing of indefinite null objects, meaning that this phenomenon depends on much finer-grained aspects than what typology alone would warrant. Nevertheless, a theory of grammar should not be a theory of English and English-like languages alone, and therefore a comprehensive model of indefinite object drop should consider a variety of typologically different languages.\\
As noted by \textcite[134]{Jackendoff2003}, languages such as Korean and Japanese allow for null arguments more easily than English, so that they would pose "no justiﬁcation for distinguishing between obligatorily and optionally expressed semantic arguments". However, in the same paragraph he also argues in favor of the distinction between definite and indefinite null objects being a fully idiosyncratic lexical property of verbs or, at most, of semantic verb classes, a position which I argued against throughout \refch{objectdrop} and \refch{factors}. Thus, it is not to be excluded that languages such as Korean and Japanese may show different degrees of acceptability of indefinite object drop with different optionally transitive verbs, even if they are free in their Topic-drop-based licensing of definite null objects (just like English and typologically similar languages are, as argued on \refpage{recipes}).\\
Another typologically different family, namely, Slavic languages, may shed light on the role played by grammatical aspect in the indefinite implicit object construction. As mentioned in \refsec{perfectivity}, simplifying a very long tradition of studies in a way that will surely disgruntle many of those who fostered research in this area, in Slavic languages perfectivity is embedded in the lexicon rather than being expressed morphologically (as in English and Italian). Should experimental evidence confirm the claim that Slavic languages do not allow for object drop with perfective verbs \parencite{sopata2016null, TsimpliPapadopoulou2006}, this would mean that \textsc{Perf Coda} acts as a hard constraint in Slavic languages, being always re-ranked above \textsc{*Int Arg} for perfective inputs (refer to \refch{medina} and \refch{model}), instead of being a soft, re-rankable constraint as it is in English and Italian. Indeed, as discussed in \refsec{telperftense}, in these two languages telicity, perfectivity and tense are intertwined, so that the interpretation of one factor partially depends on the others. This explains why in my models telicity and (secondarily) perfectivity both play a gradient role in favoring object drop, depending on each verb's semantic selectivity, despite the behavioral experiments being carefully designed to isolate the effect of each factor at play. Based on previous considerations, I hypothesize that a model of indefinite object drop in Slavic languages would paint quite a different picture.


\subsection{Different underlying math}

In this dissertation I followed \textcite{Medina2007} in providing a Stochastic Optimality Theoretic model of indefinite object drop (see \refch{medina}) where the binary predictors described in \refch{predictors} are used to define four faithfulness constraints re-ranking with respect to \textsc{*Int Arg} (a markedness constraint). Semantic selectivity, modeled along a continuous numerical scale, cannot give rise to a binary constraint itself. Instead, Medina implements it in the model by defining the probability of each faithfulness constraint re-ranking with respect to \textsc{*Int Arg} as a (linear) function of the semantic selectivity of the input verb, deviating from the Stochastic Optimality Theoretic norm of associating fixed normal curves to constraints (refer to \refsec{stochot}). However, as \textcite[110]{Medina2007} herself comments, there is no compelling reason why these re-ranking functions should be necessarily \textit{linear} functions. Indeed, she argues that linear functions are "a reasonable place to begin to explore the relative contribution of
Semantic Selectivity to the implicit object construction", and I followed in her steps to obtain models comparable to hers. Future research on indefinite object drop may benefit from employing non-linear functions, defining a more complex algorithm than the one used here to determine the best function and its parameters.\\
Going back to linear Stochastic Optimality Theoretic models of object drop, in \refsec{concl_lmem} I commented on the differences between them and linear mixed-effects models, which are linear regression models including both fixed and random effects in the computation. Mixed models, by their very nature, are able to account both for the effect of the predictors of object drop on the grammaticality of indefinite null objects (the fixed effects), and for the effect of the source of random variability in the data, i.e., the target verbs and the participants to the experiment (the aptly-named random effects). Medina's model and my own, instead, are more like classic linear regression model in that they only account for fixed effects. I minimize any effect the human participants may have had on the results by modeling their normalized ratings (refer to \refsec{likert_preprocessing}), but this pre-processing adaptation of the Likert ratings is more of a quick fix than a solid method I endorse for future research. Indeed, ideally the model should take raw ratings as input, and not only account for the different use the participants made of the Likert scale, but also quantify the amount of variance in the data depending on the participants alone. The same goes for random effects depending on the target verbs, which my models are not able to compute.

\subsection{A possible follow-up on recoverability and prototypicality}

In \refsec{whichobjects} I argued, with reference to the literature, that indefinite null objects refer to the prototypical Patients of a given transitive verb, as recovered by speakers via world knowledge. However, this prototypicality is not to be intended as a monolith. Rather, it depends on extra- and intra-linguistic context, as it is possible to argue based on \posscite{Rice1988} examples in \ref{rice_concl}. In \ref{rice1_concl}, the act of smoking is intended to refer to cigarettes, because they are the most common object of smoking in contemporary Western society, but different context (such as a mention to olden times, or a Middle-East setting) may induce a reading where the omitted object refers to a pipe or a waterpipe. In \ref{rice2_concl}, the act of drinking is linked to alcohol assumption for reasons made clear in \refch{objectdrop} and \refsec{agentaffect}, but it would necessarily refer to some other prototype were the subject a toddler or a teetotaler, let alone a non-human participant. Similarly, John may be understood to drive a bike in \ref{rice3_concl} and to read a newspaper in \ref{rice4_concl}, provided slight differences in the provided context (e.g., a downtown location to drive to, or a different reading time).

\ex. \label{rice_concl} \a. \label{rice1_concl} John smokes (cigarettes / *Marlboros / *a pipe / *SMOKING MATERIALS).
\b. \label{rice2_concl} John drinks (alcohol / *gin / *water / *coffee / *LIQUIDS).
\c. \label{rice3_concl} When he goes to Boston, John drives (a car / *a Toyota / *a motorcycle / *A VEHICLE).
\d. \label{rice4_concl} Each afternoon, John reads (a book / *Ulysses / *the newspaper / *PRINTED MATTER).

Therefore, possibly enriching some additional models I envisioned in \refsec{expandingthemodel}, it may be useful to design an experiment targeted at the prototypicality intrinsic to object recoverability. I would imagine a cloze-test experiment where subjects have to fill in the gap in sentences such as \textit{John smokes \_\_\_}, manipulating context as to have no-context sentences, common-sense contexts, and uncommon contexts. I hypothesise that there would be much greater agreement between participants relative to the fillers of common-context stimuli and no-context stimuli (where the context is inherently provided via world knowledge), than with uncommon-context stimuli (where it is difficult to imagine prototypicality). I suspect a reaction-time experiment relative to the acceptability of such object-less stimuli would yield results consistent with these expectations.