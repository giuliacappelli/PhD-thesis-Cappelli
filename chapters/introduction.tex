\setchapterpreamble[u]{\margintoc}
\chapter{Introduction}
\labch{intro}

\section{Overview} \labsec{intro_intro}

\subsection{Relevance of this thesis}

testo \posscite{CappelliLenciPISA}

% dire che non esiste un modello sperimentale italiano (solo teoria italiana o modello exp inglese)

% \textcite[176]{Prytz2016}, As far as this thesis goes, the syntactic event structural approach to implicit objects has revealed that the study of the structural sides of linguistic meaning can also shed light on the contextual, pragmatic and encyclopedic sides of meaning. Thus, further studies into the systematicity of verb meaning and possible verb-object relationships could potentially provide us with more knowledge about how we linguistically organize our knowledge of the world and how in a more general cognitive sense the narrow syntactic-semantic knowledge is associated with contextual and encyclopedic information.

\subsection{Main goals and elements of novelty}
% qui devo dire cosa voglio dimostrare nella tesi e fare riferimento a come l'ho dimostrato nel testo
testo

% Expanding on Medina's successful model of object drop, I bring several new ideas to the table:
% \begin{itemize}
%     \item quantifying semantic selectivity with two similarity-based measures, i.e. a novel computational measure I contributed to develop in \textcite{CappelliLenciPISA} (Computational PISA, see \refsec{compuPisa}), and a behavioral measure that improves on Medina's measure of Object Similarity (Behavioral PISA, see \refsec{behavPisa});
%     \item modeling the implicit object construction both in English and in Italian, comparing the performance of the two models and possible language-dependent differences in the constraint re-ranking;
%     \item computing increasingly more complex Stochastic Optimality Theoretic models of object drop, starting with Medina's three-predictor model, adding iterativity as a predictor in an intermediate model, and computing the full five-predictor model also including manner specification among the predictors.
% \end{itemize}


\section{Contents within and without} \labsec{intro_contents}

\subsection{Chapters of the thesis and their structure}
This thesis is divided into two main sections, one devoted to the review of the literature on object drop, Optimality Theory, and gradient models of indefinite null objects (from \refch{objectdrop} to \refch{medina}), and another devoted to my own experiments and the results thereof (from \refch{predictors} to \refch{model}). Let us consider each Chapter in more detail.

\paragraph{Theory and literature review}
In \nrefch{objectdrop} I will define the \textit{indefinite} implicit object construction as a deviation from the transitive prototype (see \refsec{theory_transitivity}) and in contrast with \textit{definite} object drop (see \refsec{theory_def_vs_indef}), based on the literature. In \refsec{theory_defindefinite} I will argue that there is virtually no reason why a transitive verb should not be able to participate in the indefinite implicit object construction (provided favorable aspectual, semantic, and discourse conditions), and that the implicit object is understood to be the prototypical Patient for a given sense of a given verb. In \refsec{theory_workingdef} I will provide the perspective on indefinite object drop I adopt in my experiments and throughout this thesis.\\
In \nrefch{factors} I will discuss the role played by semantic factors (recoverability, Agent affectedness, and manner specification, in \refsec{semanticfactors}), aspectual factors (telicity and perfectivity, in \refsec{aspectualfactors}), and pragmatic factors (routine, iterativity, habituality, and discourse factors, in \refsec{pragmaticfactors}) in facilitating or blocking object drop with optionally transitive verbs. After some considerations in \refsec{frequencyfail} on the reasons why corpus frequency is not included among the relevant factors, I conclude the Chapter in \refsec{factorsofchoice} with the reasoning behind my choice of predictors of object drop to be used in the experimental section of this thesis.\\
\nrefch{modeltheory} will explain the main tenets of Optimality Theory relative to syntax (in \refsec{classicot}), the reasons why standard Optimality Theory would be a bad fit for a model of the indefinite implicit object construction, and, therefore, why it is better to resort to probabilistic models of grammar that are able to account for the gradient grammaticality shown by indefinite object drop, such as Stochastic Optimality Theory (as argued in \refsec{weightedot}).\\
In particular, in this thesis I will adopt the variant of Stochastic Optimality Theory specifically designed by \textcite{Medina2007} to model indefinite object drop, which I describe and discuss in \nrefch{medina}. The contents of the input and the output will be presented in \refsec{inputmedina}. Then, the implementation of the three predictors the author used in her model (semantic selectivity, telicity, and perfectivity) will be discussed in \refsec{predictorsmedina}. The probabilistic ranking of the constraints, which I will introduce in \refsec{constraintsmedina}, will be defined in a top-down perspective (from constraint ranking as a function of semantic selectivity to object-drop probability as gradient grammaticality) in \refsec{rankingmedina}, and finally implemented in a bottom-up perspective (from the acceptability judgments to the estimation of parameters of the linear functions) in \refsec{medinacomputation}.

\paragraph{Experiments and results}
\nrefch{predictors} opens the experimental section of this thesis. I will present five facilitating factors (a continuous factor and four binary factors) of object drop I will use as predictors in my Stochastic Optimality Theoretic model, picked among the ones introduced in \refch{factors}. The continuous factor is object recoverability, which I will model via three different measures of semantic selectivity described in \refsec{predictor_sps}, namely \posscite{Resnik1993} Selectional Preference Strength (following \textcite{Medina2007}), Computational PISA (a novel measure based on distributional semantics I contributed to define in \textcite{CappelliLenciPISA}), and Behavioral PISA (a similarity-based measure inspired by Computational PISA and Medina's Object Similarity measure). The four binary factors are telicity in \refsec{predictor_telicity}, perfectivity in \refsec{predictor_perfectivity}, iterativity in \refsec{predictor_iterativity}, and manner specification in \refsec{predictor_mannspec}.\\
In \nrefch{judgments} I will present the materials and methods I employed in the behavioral experiments I have run to collect acceptability judgments from native speakers of English and Italian relative to the indefinite implicit object construction. In particular, I will describe the way I built the experiment with PsychoPy, run it on Pavlovia, and recruited participants via Prolific in \refsec{participants}, and then I will present my 30-verb target dataset in \refsec{verbs}, the experimental design in \refsec{design}, the stimuli in \refsec{stimuli}, and the experimental setting in \refsec{setting}.\\
A first analysis of the data collected with these behavioral experiments will be provided in \nrefch{results}, where I will describe the inner workings of the Python script I wrote to perform the analysis and compute the models, as well as the procedures of data preprocessing I employed (see \refsec{likert_scripts}), before discussing the separate and joint effects of semantic selectivity and the four binary predictors on the acceptability judgments in English and in Italian (see \refsec{eng_judgresult} and \refsec{ita_judgresult}, respectively). In \refsec{sumup_judgresult} I will argue that the five factors facilitating indefinite object drop are able to predict, to a non-negligible extent, the likelihood a transitive verb will appear without an overt object in a statistical (linear mixed-effects) model, and I will also explain why Medina's variant of Stochastic Optimality Theoretic is a more linguistically-motivated way of modeling these results than the linguistically-naive statistical model.\\
I will define and discuss my Stochastic Optimality Theoretic models of indefinite object drop in English and Italian in \nrefch{model}. In \refsec{introfitting} I will describe and evaluate my 18 models, stemming from the union of three measures of semantic selectivity, three increasingly more complex constraint sets (Medina's basic set, another with the addition of iterativity, and a full set with manner specification too), and two target languages. In \refsec{stot_full} I will discuss the theoretical aspects and computational implementation of the two full models of object drop in English and Italian where semantic selectivity is modeled via Behavioral PISA. I will then compare my models with Medina's model and with regression models in \refsec{stot_conclusions}.\\
Finally, I will provide my conclusions and propose some possibile future directions for research about modeling the indefinite implicit object construction in \nrefch{conclusions}.


\subsection{Supporting materials} % RIPORTARE I LINK AGLI ESPERIMENTI PAVLOVIA!
With an eye to the Open Science framework, I am using open source software and programming languages to collect and analyse data for this thesis whenever possible, and I am sharing my data, scripts and results on dedicated GitHub repositories. Should anyone in the future read these pages and find themselves interested in replicating my results, or testing new models on the data I collected, or contributing to enrich my repositories, they will be able to do so \href{https://github.com/giuliacappelli}{on my GitHub profile}\sidenote{https://github.com/giuliacappelli}.\\ %  effortlessly (and without spending money on proprietary software)
The interested reader will find my data, i.e. the stimuli for each experiment and the raw results I got from participants, \href{https://github.com/giuliacappelli/dissertationData}{in a dedicated GitHub repository}\sidenote{https://github.com/giuliacappelli/ dissertationData}. In more detail, this repository contains:
\begin{itemize}
    \item 30 target verbs and 10 filler verbs both for English and for Italian, used in all the computational (see \refsec{predictor_sps}) and behavioral (see \refsec{behavPisa} and \refch{judgments}) experiments, as in \refapp{app_verbs};
    \item full lists of the direct objects of each target verb as extracted from the ukWaC corpus for English and from itWaC for Italian, both raw and manually cleaned (as detailed in \refsec{compuPisa});
    \item stimuli, full judgments elicited from 25 participants per language on a 7-point Likert scale, and final scores obtained in the Behavioral PISA experiment (see \refsec{behavPisa}), also provided in \refapp{app_behavPisa};
    \item each verb tagged with its features relative to the verb-specific predictors of object drop, i.e. telicity, manner specification, and semantic selectivity, as in \refapp{app_predictors};
    \item stimuli and full judgments elicited from 30 participants per language on a 7-point Likert scale in the main behavioral experiment of this thesis (see \refch{judgments}), aimed towards creating a Stochastic Optimality Theoretic model of object drop in English and Italian (see \refch{model}), as in \refapp{app_stimuli}.
\end{itemize}
As for the data processing, analysis of results, computational implementation of experimental designs, and creation of stimuli, I coded several Python scripts and documented their usage on GitHub. In detail, they are as follows:
\begin{itemize}    
    \item \href{https://github.com/giuliacappelli/checkPolysemy}{Quantify the polysemy of words in a list}\sidenote{https://github.com/giuliacappelli/ checkPolysemy} using WordNet (Wu-Palmer Similarity), as in \refsec{verbs};
    \item \href{https://github.com/giuliacappelli/behavioralPISA}{Behavioral PISA}\sidenote{https://github.com/giuliacappelli/ behavioralPISA}, a (behavioral) measure of Preference In Selection of Arguments to model verb argument recoverability, as in \refsec{behavPisa}. The script takes care both of creating the stimuli for the experiment and of generating Behavioral PISA scores based on the Likert-scale acceptability judgments provided by human participants;
    \item \href{https://github.com/giuliacappelli/psychopy_exps}{PsychoPy Builder source code}\sidenote{https://github.com/giuliacappelli/ psychopy\_exps} of my behavioral experiments to collect acceptability judgments relative to the indefinite implicit object construction from native speakers of English and Italian, described in \refch{judgments};
    \item \href{https://github.com/giuliacappelli/PsychopyToMedina}{Psychopy-to-Medina converter}\sidenote{https://github.com/giuliacappelli/ PsychopyToMedina}, to convert the output of my PsychoPy behavioral experiment (see \refch{judgments}) into a suitable input for my scripts to analyse the results (see \refch{results}) and create Stochastic OT models of the implicit object construction following \textcite{Medina2007} (see \refch{model});
    \item \href{https://github.com/giuliacappelli/MedinaStochasticOptimalityTheory}{Modeling the grammaticality of implicit objects}\sidenote{https://github.com/giuliacappelli/ MedinaStochasticOptimalityTheory} based on Medina (2007)'s variant of Stochastic Optimality Theory, as in \refch{results} and \refch{model};
    \item \href{https://github.com/giuliacappelli/generateMockLikertGrammaticalityJudgments}{Generate mock Likert-scale acceptability judgments}\sidenote{https://github.com/giuliacappelli/ generateMockLikertGrammaticalityJudgments} based on factor levels specified in the input, to test the above Stochastic Optimality Theoretic model on ideal data before running the experiment proper.
\end{itemize}

\subsection{Published work and outreach}
Relevant parts of the experimental section of this thesis have been shared with the scientific community, both in written form and during conferences. The original distributional measure of Preference In Selection of Arguments (Computational PISA) presented in \textcite{CappelliLenciPISA} and discussed here in \refsec{compuPisa}, tested on large sets of transitive verbs and Instrument verbs in English, was presented at:
\begin{itemize}
    \item *SEM 2020, 9th Joint Conference on Lexical and Computational Semantics, December 12-13th 2020, online due to the Covid-19 pandemic (originally in Barcelona, Spain);
    \item LSA 2021, 95th Annual Meeting of the Linguistic Society of America, January 7-10th 2021, online due to the Covid-19 pandemic (originally in San Francisco, California);
    \item CLiC-it 2020, 7th Italian Conference on Computational Linguistics, March 1-3rd 2021, online due to the Covid-19 pandemic (originally in Bologna, Italy).
\end{itemize}
The results of the main behavioral experiment of this thesis (detailed in \refch{judgments} and \refch{results}), especially the ones pertaining to Italian, were presented at:
\begin{itemize}
    \item SyntOp 2022, Syntactic Optionality in Italian, July 4-5th 2022, Venice (Italy).
\end{itemize}