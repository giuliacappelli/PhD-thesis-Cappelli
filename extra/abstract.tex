\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract} % Add the preface to the table of contents as a chapter

This thesis is about the omission of direct objects from predicates headed by verbs taking two semantic participants, i.e., an Agent (in the syntactic subject position) and a Patient (in the syntactic object position). These "optionally transitive" verbs, deviating from the transitive prototype defined by \textcite{HopperThompson1980}, appear in a wide variety of contexts cross-linguistically, and are licensed by different semantic, aspectual, pragmatic, and discourse factors. Within this broad area of interest, I will focus on \textit{indefinite} null objects, corresponding to what \textcite{Fillmore1986} called "indefinite null complements". These omitted objects, as shown in \ref{introintro1}, refer to something that is "unknown or a matter of indifference" \parencite[96]{Fillmore1986}.

\textcite{Medina2007} made a substantial step in this EXPERIMENTAL direction in her (linear) Stochastic Optimality Theoretic model of indefinite object drop in English, taking into consideration the joint effect of object recoverability, telicity, and perfectivity on the grammaticality of indefinite null objects (as gauged via gradient acceptability judgments elicited from native speakers) occurring with 30 transitive verbs. This model shows that:
\begin{itemize}
    \item indefinite object drop is a gradient, non-categorical phenomenon;
    \item it is possible with virtually any transitive verb, but in different degrees depending on the verb semantics;
    \item for any given verb, different aspectual feature may favor or hinder object drop.
\end{itemize}

I add several elements of novelty to the study:
\begin{itemize}
    \item I will model indefinite implicit objects both in English (like Medina did) and in Italian (which is included in such a probabilistic model for the first time), analyzing language-specific differences in the way several factors facilitate object drop;
    \item in addition to using \posscite{Resnik1993} Selectional Preference Strength measure to quantify semantic selectivity (as a proxy to object recoverability), following \textcite{Medina2007}, I will also define a novel computational measure based on distributional semantics (Computational PISA, presented in \textcite{CappelliLenciPISA}) and a behavioral measure (Behavioral PISA) meant to improve on Medina's Object Similarity;
    \item in addition to the three predictors included by Medina in her model (semantic selectivity, telicity, and perfectivity), I will also add iterativity and manner specification as predictors in my models to find out how they affect indefinite object drop and if a more complex, five-predictor model actually provides a more accurate view on this phenomenon than the original three-predictor model;
    \item in order to make it easier for future research to build on my results (possibly applying my method to other languages, or to the same languages with different predictors) or to replicate them, I will share my materials and document my methods (as well as my Python scripts), as detailed in \refsec{supportingmaterials}.
\end{itemize}

In general, they perform comparably well, explaining almost half of the variance in the data (adjusted R\textsuperscript{2} is 0.468 for the English model and 0.455 for the Italian model, as reported in \refsec{intro_evaluation}).

Thus, both models show a main effect of telicity on the probability the object-less use of a transitive verb will be considered grammatical, but the second most relevant factor in the model is perfectivity in English and manner specification in Italian.\\
In addition to the adjusted R\textsuperscript{2} values and the main role played by telicity, the two models are also comparable for the range of predicted object-dropping probabilities (30-100\% in English, 30-90\% in Italian), for the relevance of semantic selectivity in determining the grammaticality of object drop (with re-ranking probabilities that are always directly proportional to Behavioral PISA, with the exception of \textsc{Telic End} in Italian), and for the fact that the predictors perform consistently with theoretical literature on object drop. Indeed, in both models atelic imperfective iterative manner-specified inputs are the most likely to drop their object (between 80\% and 90\%), while telic perfective non-iterative manner-unspecified inputs are the least likely (between 30\% and 40\%). Moreover, atelic inputs are more likely to occur with implicit objects than telic inputs, imperfective inputs more than perfective inputs, iterative inputs more than non-iterative inputs, and manner-unspecified inputs more than manner-specified inputs, as expected.\\

The full five-predictor models explain the variance in the data better than the three- and the four-predictor models regardless of the chosen measure of semantic selectivity (Resnik's SPS, Computational PISA, or Behavioral PISA). However, the four-predictor models (including iterativity in addition to Medina's telicity, perfectivity, and semantic selectivity) do not perform better than the three-predictor models, with basically identical adjusted R\textsuperscript{2} values in English and slightly smaller adjusted R\textsuperscript{2} values in Italian. Taken together, these results mean that iterativity alone is not a sufficient addition to Medina's model (rather, it makes the model needlessly more complicated, since it does not explain more variance in the data), but models including iterativity and manner specification together have a noticeably stronger explanatory power.

I showed that the addition of manner specification determines a much stronger qualitative leap in the full models of Italian than in English, where the increase in the performance of the models is rather modest.

In English SPS-based models are the worst-performing, while PISA-based models are noticeably better (with Behavioral PISA being better than Computational PISA). In Italian, instead, Computational PISA-based models are the worst-performing among all, followed by SPS-based models and, lastly, by Behavioral PISA-based models.

 I argued that the English facts (SPS-based models being worse than PISA-based models, and SPS correlating poorly with PISAs while Behavioral PISA and Computational PISA correlate well with each other) may depend on the nature of these measures, considering that both PISA measures are based on the computation of pairwise similarity scores (distributional cosine similarity for Computational PISA, Likert-scale human judgments of similarity for Behavioral PISA), while SPS suffers from all the problems of taxonomy-based measures, as discussed in \refsec{predictor_sps}. The Italian picture is different, since in this case Computational PISA-based models perform worse than SPS-based models. Interestingly, as shown in \refsec{ita_judgresult_semsel}, Computational PISA in Italian correlates very well with SPS (even better than with Behavioral PISA). I take this to mean that even after the manual cleansing I performed to purge any artifacts from the corpus data (recounted and motivated on \refpage{cleanthecorpus}), the itWaC corpus, upon which I based the computation of SPS and Computational PISA relative to Italian, has a stronger effect on the resulting scores than the ukWaC corpus, which I used to model the computational measures of semantic selectivity in English.
 
%  However, there may also be some undesirable side effect generated by the choice of ukWaC for English, given that 
 I was able to reproduce Medina's findings relative to indefinite object drop in English with my three-predictor PISA-based models, but not with SPS, which is the measure she herself used (refer to \refsec{concl_medinacompare}).
 
 To conclude, I observe that both in English and in Italian the best-performing models are based on Behavioral PISA. This result does not surprise at all, since this measure, due to being based on human similarity judgments, can be considered a benchmark model of semantic selectivity.
